# Machine-Learning-Final-Project-1

# preprocessing and feature engineering:
Yamen: 
• Data ingestion
• memory-savvy joins
• Distribution plots for numeric features and target(s) (histogram, density).
• Categorical cardinality analysis (barplots / top-k frequencies).
• Cleaning & Imputation
• Feature scaling
• User×Product interaction features
• Temporal features

Soode:
• User-level features
• Product-level features

# Task A:
Yamen: 
• K-Nearest Neighbors classifier

Soode: 
• Logistic Regression (with L1/L2, class weights)
• Support Vector Machine (linear + kernel — must explain computational limits)
• Decision Tree classifier
• Random Forest classifier
• Gradient boosting classifier (XGBoost / LightGBM) — required

# Task B:
Yamen & Soode: 
• K-Nearest Neighbors Regressor & Ordinary Least Squares / Linear Regression

